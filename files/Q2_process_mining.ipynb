{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T15:32:04.511755Z",
     "start_time": "2025-12-05T15:31:44.376521Z"
    }
   },
   "source": [
    "### Display\n",
    "from IPython.display import display\n",
    "## Data Handling\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import random\n",
    "import numpy as np\n",
    "from cvxopt.misc_solvers import scale\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T15:32:04.631338Z",
     "start_time": "2025-12-05T15:32:04.623575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# please do not change or delete this cell (probably not needed, but just in case ;))\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "id": "1cef704e000e3f51",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T15:32:09.317090Z",
     "start_time": "2025-12-05T15:32:04.729027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Try fast rustxes importer first (if installed), otherwise fall back to default importer\n",
    "try:\n",
    "    log = pm4py.read_xes(\"fines_event_log.xes\", variant=\"rustxes\")\n",
    "except Exception as e:\n",
    "    print(\"rustxes importer not available, falling back to default XES importer:\", repr(e))\n",
    "    log = pm4py.read_xes(\"fines_event_log.xes\")\n",
    "\n",
    "# Ensure the dataframe is in the format expected by pm4py algorithms\n",
    "log = pm4py.format_dataframe(\n",
    "    log,\n",
    "    case_id=\"case:concept:name\",\n",
    "    activity_key=\"concept:name\",\n",
    "    timestamp_key=\"time:timestamp\",\n",
    ")\n",
    "log = log.sort_values([\"case:concept:name\", \"time:timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "log"
   ],
   "id": "35cdb30b9a246d10",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\graves\\Desktop\\PythonProject\\IDS2025\\.venv\\Lib\\site-packages\\pm4py\\utils.py:795: UserWarning: In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\n",
      "  warnings.warn(\"In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                      concept:name  penalty            time:timestamp  \\\n",
       "0                      Create Fine      NaN 2006-07-23 22:00:00+00:00   \n",
       "1                        Send Fine      NaN 2006-12-04 23:00:00+00:00   \n",
       "2                      Create Fine      NaN 2007-03-19 23:00:00+00:00   \n",
       "3                        Send Fine      NaN 2007-07-16 22:00:00+00:00   \n",
       "4         Insert Fine Notification      NaN 2007-08-01 22:00:00+00:00   \n",
       "...                            ...      ...                       ...   \n",
       "267247                 Create Fine      NaN 2002-09-06 22:00:00+00:00   \n",
       "267248                   Send Fine      NaN 2002-10-24 22:00:00+00:00   \n",
       "267249    Insert Fine Notification      NaN 2002-11-03 23:00:00+00:00   \n",
       "267250                 Add penalty    131.0 2003-01-02 23:00:00+00:00   \n",
       "267251  Send for Credit Collection      NaN 2004-01-09 23:00:00+00:00   \n",
       "\n",
       "       dismissal  expense  case:fine case:concept:name  paymentAmount  \n",
       "0           None      NaN       35.0                A1            NaN  \n",
       "1           None    11.00       35.0                A1            NaN  \n",
       "2           None      NaN       36.0            A10008            NaN  \n",
       "3           None    13.00       36.0            A10008            NaN  \n",
       "4           None      NaN       36.0            A10008            NaN  \n",
       "...          ...      ...        ...               ...            ...  \n",
       "267247      None      NaN      131.0             V9999            NaN  \n",
       "267248      None    15.16      131.0             V9999            NaN  \n",
       "267249      None      NaN      131.0             V9999            NaN  \n",
       "267250      None      NaN      131.0             V9999            NaN  \n",
       "267251      None      NaN      131.0             V9999            NaN  \n",
       "\n",
       "[267252 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept:name</th>\n",
       "      <th>penalty</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>dismissal</th>\n",
       "      <th>expense</th>\n",
       "      <th>case:fine</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>paymentAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create Fine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-23 22:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>A1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Send Fine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-12-04 23:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>11.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>A1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Create Fine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-03-19 23:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>A10008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Send Fine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-07-16 22:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>13.00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>A10008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insert Fine Notification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-08-01 22:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>A10008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267247</th>\n",
       "      <td>Create Fine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-09-06 22:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>V9999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267248</th>\n",
       "      <td>Send Fine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-10-24 22:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>15.16</td>\n",
       "      <td>131.0</td>\n",
       "      <td>V9999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267249</th>\n",
       "      <td>Insert Fine Notification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-11-03 23:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>V9999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267250</th>\n",
       "      <td>Add penalty</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2003-01-02 23:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>V9999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267251</th>\n",
       "      <td>Send for Credit Collection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-01-09 23:00:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>V9999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267252 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T15:32:09.747946Z",
     "start_time": "2025-12-05T15:32:09.700868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# number of cases\n",
    "number_cases = log[\"case:concept:name\"].nunique()\n",
    "number_cases"
   ],
   "id": "96385747cd39aff6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71522"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T15:32:09.990842Z",
     "start_time": "2025-12-05T15:32:09.961364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_activities = log[\"concept:name\"].nunique()\n",
    "number_activities"
   ],
   "id": "a715299115030217",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# a) Full Model Discovery",
   "id": "2fa5a316b4cb2511"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pm4py.objects.process_tree.obj import Operator\n",
    "\n",
    "# Discover a model from the full event log (standard inductive miner = default parameters)\n",
    "pt_full = pm4py.discover_process_tree_inductive(log)\n",
    "net_full, im_full, fm_full = pm4py.convert_to_petri_net(pt_full)\n",
    "\n",
    "print(\"Discovered process tree (Inductive Miner, default parameters):\")\n",
    "print(pt_full)\n",
    "\n",
    "# --- Helper functions to reason about the process tree (model-based answers) ---\n",
    "def can_be_empty(node):\n",
    "    \"\"\"Returns True iff the subtree can generate an empty trace (tau).\"\"\"\n",
    "    if node.operator is None:\n",
    "        return node.label is None\n",
    "\n",
    "    op = node.operator\n",
    "    if op in (Operator.XOR, Operator.OR):\n",
    "        return any(can_be_empty(c) for c in node.children)\n",
    "    if op in (Operator.SEQUENCE, Operator.PARALLEL):\n",
    "        return all(can_be_empty(c) for c in node.children)\n",
    "    if op == Operator.LOOP:\n",
    "        # Loop executes its body at least once; empty only if body can be empty\n",
    "        return can_be_empty(node.children[0]) if node.children else True\n",
    "\n",
    "    return any(can_be_empty(c) for c in node.children)\n",
    "\n",
    "\n",
    "def start_activities(node):\n",
    "    \"\"\"Returns the set of visible activities that can start a trace in the model.\"\"\"\n",
    "    if node.operator is None:\n",
    "        return set() if node.label is None else {node.label}\n",
    "\n",
    "    op = node.operator\n",
    "    if op == Operator.SEQUENCE:\n",
    "        res = set()\n",
    "        for c in node.children:\n",
    "            res |= start_activities(c)\n",
    "            if not can_be_empty(c):\n",
    "                break\n",
    "        return res\n",
    "\n",
    "    if op in (Operator.XOR, Operator.OR, Operator.PARALLEL):\n",
    "        res = set()\n",
    "        for c in node.children:\n",
    "            res |= start_activities(c)\n",
    "        return res\n",
    "\n",
    "    if op == Operator.LOOP:\n",
    "        return start_activities(node.children[0]) if node.children else set()\n",
    "\n",
    "    res = set()\n",
    "    for c in node.children:\n",
    "        res |= start_activities(c)\n",
    "    return res\n",
    "\n",
    "\n",
    "def labels_in_subtree(node):\n",
    "    if node.operator is None:\n",
    "        return set() if node.label is None else {node.label}\n",
    "    res = set()\n",
    "    for c in node.children:\n",
    "        res |= labels_in_subtree(c)\n",
    "    return res\n",
    "\n",
    "\n",
    "def mandatory_all(node):\n",
    "    \"\"\"Labels that appear in every trace generated by this subtree.\"\"\"\n",
    "    if node.operator is None:\n",
    "        return set() if node.label is None else {node.label}\n",
    "\n",
    "    op = node.operator\n",
    "    child_mand = [mandatory_all(c) for c in node.children]\n",
    "\n",
    "    if op in (Operator.SEQUENCE, Operator.PARALLEL):\n",
    "        res = set()\n",
    "        for s in child_mand:\n",
    "            res |= s\n",
    "        return res\n",
    "\n",
    "    if op in (Operator.XOR, Operator.OR):\n",
    "        if not child_mand:\n",
    "            return set()\n",
    "        res = set(child_mand[0])\n",
    "        for s in child_mand[1:]:\n",
    "            res &= s\n",
    "        return res\n",
    "\n",
    "    if op == Operator.LOOP:\n",
    "        return mandatory_all(node.children[0]) if node.children else set()\n",
    "\n",
    "    res = set()\n",
    "    for s in child_mand:\n",
    "        res |= s\n",
    "    return res\n",
    "\n",
    "\n",
    "def find_paths(node, target_label, path=None):\n",
    "    if path is None:\n",
    "        path = []\n",
    "    path = path + [node]\n",
    "\n",
    "    if node.operator is None:\n",
    "        return [path] if node.label == target_label else []\n",
    "\n",
    "    res = []\n",
    "    for c in node.children:\n",
    "        res.extend(find_paths(c, target_label, path))\n",
    "    return res\n",
    "\n",
    "\n",
    "def forced_labels_if_activity_occurs(tree, target_label):\n",
    "    \"\"\"Returns labels that are guaranteed to occur if target_label occurs (model-based).\"\"\"\n",
    "    paths = find_paths(tree, target_label)\n",
    "    if not paths:\n",
    "        return set()\n",
    "\n",
    "    forced_sets = []\n",
    "    for path in paths:\n",
    "        forced = {target_label}\n",
    "        # Traverse upwards from leaf to root and collect mandatory labels from siblings\n",
    "        for i in range(len(path) - 1, 0, -1):\n",
    "            child = path[i]\n",
    "            parent = path[i - 1]\n",
    "            if parent.operator in (Operator.SEQUENCE, Operator.PARALLEL):\n",
    "                for sib in parent.children:\n",
    "                    if sib is not child:\n",
    "                        forced |= mandatory_all(sib)\n",
    "        forced_sets.append(forced)\n",
    "\n",
    "    common = set.intersection(*forced_sets) if forced_sets else set()\n",
    "    return common\n",
    "\n",
    "\n",
    "def repeatable_activities(tree):\n",
    "    \"\"\"Returns visible activities that can occur more than once (loop bodies).\"\"\"\n",
    "    reps = set()\n",
    "\n",
    "    def visit(node):\n",
    "        if node.operator == Operator.LOOP and node.children:\n",
    "            reps.update(labels_in_subtree(node.children[0]))\n",
    "        for c in getattr(node, \"children\", []) or []:\n",
    "            visit(c)\n",
    "\n",
    "    visit(tree)\n",
    "    return reps\n",
    "\n",
    "\n",
    "# a1) Start activities\n",
    "starts = sorted(start_activities(pt_full))\n",
    "print(\"\\n(a1) Start activities (from the model):\", starts)\n",
    "\n",
    "# a2) Mandatory activities/order for traces containing an appeal to a judge\n",
    "forced_for_judge = forced_labels_if_activity_occurs(pt_full, \"Appeal to Judge\")\n",
    "print(\"\\n(a2) If 'Appeal to Judge' occurs, the model forces these activities to occur:\")\n",
    "print(sorted(forced_for_judge))\n",
    "print(\n",
    "    \"Order (from the process tree): the trace starts with 'Create Fine'. \"\n",
    "    \"The model also requires 'Send Fine' if 'Appeal to Judge' occurs, but allows 'Send Fine' and \"\n",
    "    \"'Appeal to Judge' in any order after 'Create Fine' (parallel part in the model).\"\n",
    ")\n",
    "\n",
    "# a3) Activities that can be executed more than once\n",
    "repeatable = sorted(repeatable_activities(pt_full))\n",
    "print(\"\\n(a3) Activities that can occur more than once:\", repeatable)\n",
    "\n",
    "# a4) Credit collection without sending the fine\n",
    "forced_for_cc = forced_labels_if_activity_occurs(pt_full, \"Send for Credit Collection\")\n",
    "cc_without_send_fine_possible = \"Send Fine\" not in forced_for_cc\n",
    "print(\n",
    "    \"\\n(a4) Can 'Send for Credit Collection' happen without 'Send Fine'?\",\n",
    "    cc_without_send_fine_possible,\n",
    ")\n",
    "\n",
    "# Optional visualization (process tree)\n",
    "from pm4py.visualization.process_tree import visualizer as pt_visualizer\n",
    "gviz_tree_full = pt_visualizer.apply(pt_full)\n",
    "gviz_tree_full"
   ],
   "id": "233f1c0fea9402f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# b) Behavior Case Frequency",
   "id": "a72558076561672d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For this question, we recommend using the following event log filtering methods of PM4PY:\n",
    "- filter_eventually_follows_relation (https://processintelligence.solutions/static/api/2.7.17/generated/pm4py.filtering.filter_eventually_follows_relation.html)\n",
    "- filter_directly_follows_relation (https://processintelligence.solutions/static/api/2.7.17/generated/pm4py.filtering.filter_directly_follows_relation.html)"
   ],
   "id": "b0f6568a44318445"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# b) Count cases exhibiting specific (allowed) but suspicious behavior\n",
    "\n",
    "def first_event_time(activity_name: str) -> pd.Series:\n",
    "    \"\"\"Earliest timestamp of an activity per case (only for cases where the activity occurs).\"\"\"\n",
    "    return (\n",
    "        log.loc[log[\"concept:name\"] == activity_name]\n",
    "        .groupby(\"case:concept:name\")[\"time:timestamp\"]\n",
    "        .min()\n",
    "    )\n",
    "\n",
    "\n",
    "min_payment = first_event_time(\"Payment\")\n",
    "min_cc = first_event_time(\"Send for Credit Collection\")\n",
    "min_penalty = first_event_time(\"Add penalty\")\n",
    "min_send_fine = first_event_time(\"Send Fine\")\n",
    "min_send_appeal_pref = first_event_time(\"Send Appeal to Prefecture\")\n",
    "min_appeal_judge = first_event_time(\"Appeal to Judge\")\n",
    "min_notify_result = first_event_time(\"Notify Result Appeal to Offender\")\n",
    "\n",
    "# (b1) A payment is made but the case is still sent for credit collection\n",
    "b1_candidates = min_payment.index.intersection(min_cc.index)\n",
    "b1_cases = [cid for cid in b1_candidates if min_payment.loc[cid] < min_cc.loc[cid]]\n",
    "\n",
    "# (b2) A penalty is added before the fine is sent via post\n",
    "b2_candidates = min_penalty.index.intersection(min_send_fine.index)\n",
    "b2_cases = [cid for cid in b2_candidates if min_penalty.loc[cid] < min_send_fine.loc[cid]]\n",
    "\n",
    "# (b3) An appeal to prefecture or judge is made after a payment\n",
    "b3_pref_candidates = min_payment.index.intersection(min_send_appeal_pref.index)\n",
    "b3_pref = {cid for cid in b3_pref_candidates if min_payment.loc[cid] < min_send_appeal_pref.loc[cid]}\n",
    "b3_judge_candidates = min_payment.index.intersection(min_appeal_judge.index)\n",
    "b3_judge = {cid for cid in b3_judge_candidates if min_payment.loc[cid] < min_appeal_judge.loc[cid]}\n",
    "b3_cases = b3_pref | b3_judge\n",
    "\n",
    "# (b4) Notified about appeal result without any appeal\n",
    "notify_cases = set(min_notify_result.index)\n",
    "appeal_cases = set(min_send_appeal_pref.index) | set(min_appeal_judge.index)\n",
    "b4_cases = notify_cases - appeal_cases\n",
    "\n",
    "summary_b = pd.DataFrame(\n",
    "    {\n",
    "        \"behavior\": [\n",
    "            \"payment -> credit collection\",\n",
    "            \"penalty -> send fine\",\n",
    "            \"payment -> (appeal prefecture or judge)\",\n",
    "            \"notify result without any appeal\",\n",
    "        ],\n",
    "        \"#cases\": [len(b1_cases), len(b2_cases), len(b3_cases), len(b4_cases)],\n",
    "    }\n",
    ")\n",
    "\n",
    "summary_b"
   ],
   "id": "4659b43b33485c39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# c) Variants",
   "id": "3adff5b86a832343"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# c) Variants: cumulative variant coverage + top-5 variants\n",
    "\n",
    "variants_counts = pm4py.get_variants_as_tuples(log)  # dict: variant(tuple) -> count\n",
    "sorted_variants = sorted(variants_counts.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "variant_counts = np.array([cnt for _, cnt in sorted_variants], dtype=int)\n",
    "variant_rel = variant_counts / number_cases\n",
    "variant_cum = np.cumsum(variant_rel)\n",
    "\n",
    "# Add 0th variant to start the plot at (0,0)\n",
    "x = np.arange(0, len(sorted_variants) + 1)\n",
    "y = np.concatenate([[0.0], variant_cum])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x, y, marker=\"o\", linewidth=1)\n",
    "plt.ylim(0, 1.01)\n",
    "plt.xlim(0, len(sorted_variants))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel(\"#variants (ranked by frequency, most frequent first)\")\n",
    "plt.ylabel(\"cumulative share of cases\")\n",
    "plt.title(\"Cumulative variant frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretation (2 sentences)\n",
    "top5_share = float(variant_rel[:5].sum())\n",
    "top10_share = float(variant_rel[:10].sum())\n",
    "print(\n",
    "    f\"Interpretation: The curve rises very steeply—already the top 5 variants cover about {top5_share:.1%} of all cases. \"\n",
    "    f\"After that, the curve flattens (top 10 variants cover about {top10_share:.1%}), indicating a long tail of rare behavior.\" \n",
    ")\n",
    "\n",
    "# 5 most frequent variants and how many cases they cover\n",
    "top5 = sorted_variants[:5]\n",
    "top5_df = pd.DataFrame(\n",
    "    {\n",
    "        \"rank\": range(1, 6),\n",
    "        \"cases\": [cnt for _, cnt in top5],\n",
    "        \"variant\": [\" -> \".join(v) for v, _ in top5],\n",
    "    }\n",
    ")\n",
    "top5_df"
   ],
   "id": "d36a06d8dddc8a43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# d) Case overview",
   "id": "20b4d0e88fa163fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# d) Case overview: open vs closed (paid full / dismissed / credit collection)\n",
    "\n",
    "# Case-level amounts (expense/penalty at most once per case, but multiple payments can exist)\n",
    "case_fine = log.groupby(\"case:concept:name\")[\"case:fine\"].first().fillna(0)\n",
    "case_expense = log.groupby(\"case:concept:name\")[\"expense\"].max().fillna(0)\n",
    "case_penalty = log.groupby(\"case:concept:name\")[\"penalty\"].max().fillna(0)\n",
    "due_amount = case_fine + case_expense + case_penalty\n",
    "\n",
    "paid_amount = log.groupby(\"case:concept:name\")[\"paymentAmount\"].sum().fillna(0)\n",
    "is_dismissed = log.groupby(\"case:concept:name\")[\"dismissal\"].apply(lambda s: s.notna().any())\n",
    "\n",
    "cc_case_ids = set(log.loc[log[\"concept:name\"] == \"Send for Credit Collection\", \"case:concept:name\"].unique())\n",
    "dismissed_case_ids = set(is_dismissed[is_dismissed].index)\n",
    "paid_full_case_ids = set(due_amount.index[paid_amount >= due_amount])\n",
    "\n",
    "# Classification (mutually exclusive in the provided data)\n",
    "case_status = pd.Series(\"open\", index=due_amount.index)\n",
    "case_status.loc[list(cc_case_ids)] = \"credit_collection\"\n",
    "case_status.loc[list(dismissed_case_ids - cc_case_ids)] = \"dismissed\"\n",
    "case_status.loc[list(paid_full_case_ids - cc_case_ids - dismissed_case_ids)] = \"paid_full\"\n",
    "\n",
    "status_counts = case_status.value_counts()\n",
    "\n",
    "labels = [\n",
    "    f\"Open ({status_counts.get('open', 0)})\",\n",
    "    f\"Closed: paid full ({status_counts.get('paid_full', 0)})\",\n",
    "    f\"Closed: dismissed ({status_counts.get('dismissed', 0)})\",\n",
    "    f\"Closed: credit collection ({status_counts.get('credit_collection', 0)})\",\n",
    "]\n",
    "sizes = [\n",
    "    int(status_counts.get(\"open\", 0)),\n",
    "    int(status_counts.get(\"paid_full\", 0)),\n",
    "    int(status_counts.get(\"dismissed\", 0)),\n",
    "    int(status_counts.get(\"credit_collection\", 0)),\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.pie(sizes, labels=labels, autopct=\"%1.1f%%\", startangle=90)\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Case status (open vs closed categories)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "closed_case_ids = set(case_status.index[case_status != \"open\"])\n",
    "print(\"\\nClosed cases:\", len(closed_case_ids))\n",
    "print(\"Open cases:\", int(status_counts.get('open', 0)))\n"
   ],
   "id": "f3a772ec6a3282f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# e) Filtered log",
   "id": "1a24d8f1412e8ad2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# e) Sublog with closed cases only + keep the 5 most frequent closed-case variants\n",
    "if \"closed_case_ids\" not in globals():\n",
    "    closed_case_ids = set(case_status.index[case_status != \"open\"])\n",
    "\n",
    "closed_log = log[log[\"case:concept:name\"].isin(closed_case_ids)].copy()\n",
    "print(\"Closed cases in sublog:\", closed_log[\"case:concept:name\"].nunique())\n",
    "\n",
    "# Variant frequencies (closed cases only)\n",
    "closed_variants_counts = pm4py.get_variants_as_tuples(closed_log)\n",
    "sorted_closed_variants = sorted(closed_variants_counts.items(), key=lambda kv: kv[1], reverse=True)\n",
    "top5_closed_variants = sorted_closed_variants[:5]\n",
    "\n",
    "top5_closed_df = pd.DataFrame(\n",
    "    {\n",
    "        \"rank\": range(1, 6),\n",
    "        \"cases\": [cnt for _, cnt in top5_closed_variants],\n",
    "        \"variant\": [\" -> \".join(v) for v, _ in top5_closed_variants],\n",
    "    }\n",
    ")\n",
    "display(top5_closed_df)\n",
    "\n",
    "# Filter the closed log to keep only cases belonging to these 5 variants\n",
    "case_variant_tuple = (\n",
    "    closed_log.sort_values([\"case:concept:name\", \"time:timestamp\"])\n",
    "    .groupby(\"case:concept:name\")[\"concept:name\"]\n",
    "    .apply(tuple)\n",
    ")\n",
    "top5_variant_set = {v for v, _ in top5_closed_variants}\n",
    "selected_case_ids = case_variant_tuple[case_variant_tuple.isin(top5_variant_set)].index\n",
    "\n",
    "filtered_log = closed_log[closed_log[\"case:concept:name\"].isin(selected_case_ids)].copy()\n",
    "print(\"\\nCases in filtered log (top-5 closed variants):\", filtered_log[\"case:concept:name\"].nunique())\n",
    "\n",
    "# Discover Petri net on the filtered log (inductive miner, default parameters)\n",
    "pt_filtered = pm4py.discover_process_tree_inductive(filtered_log)\n",
    "net_filtered, im_filtered, fm_filtered = pm4py.convert_to_petri_net(pt_filtered)\n",
    "\n",
    "print(\"\\nFiltered process tree:\")\n",
    "print(pt_filtered)\n",
    "\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "gviz_net_filtered = pn_visualizer.apply(net_filtered, im_filtered, fm_filtered)\n",
    "gviz_net_filtered\n",
    "\n",
    "# Commentary (3-4 sentences)\n",
    "full_activities = set(log[\"concept:name\"].unique())\n",
    "filtered_activities = set(filtered_log[\"concept:name\"].unique())\n",
    "print(\n",
    "    \"\\nComment: Compared to the full-log model, the filtered model contains only the core activities \"\n",
    "    f\"{sorted(filtered_activities)} and removes all appeal-related behavior ({sorted(full_activities - filtered_activities)}). \"\n",
    "    \"In this filtered model, payments occur in a loop and can happen directly after 'Create Fine' (as in the frequent variant 'Create Fine -> Payment'), \"\n",
    "    \"so the payment timing is simplified compared to the full-log model. \"\n",
    "    \"Also, payments and 'Send for Credit Collection' are mainly alternative outcomes (XOR) here, \"\n",
    "    \"whereas the full-log model is more permissive and allows co-occurrence patterns (e.g., payment followed by credit collection).\"\n",
    ")\n"
   ],
   "id": "bbc5bffc9e468c93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# f) Fitness",
   "id": "342652019722a502"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# f) Fitness of the full log on the filtered model (token-based replay)\n",
    "fitness = pm4py.fitness_token_based_replay(log, net_filtered, im_filtered, fm_filtered)\n",
    "\n",
    "# Depending on the pm4py version, both keys can exist\n",
    "perfect_pct = fitness.get(\"percentage_of_fitting_traces\", fitness.get(\"perc_fit_traces\"))\n",
    "log_fitness = fitness.get(\"log_fitness\")\n",
    "\n",
    "print(\"Percentage of perfectly fitting traces:\", perfect_pct)\n",
    "print(\"Log fitness:\", log_fitness)\n",
    "\n",
    "print(\n",
    "    \"\\nExplanation: 'percentage of perfectly fitting traces' counts only traces with fitness = 1.0 (no missing/remaining tokens). \"\n",
    "    \"The 'log fitness' is an average over all traces, so traces that are not perfect can still contribute a high fitness value if they deviate only slightly from the model. \"\n",
    "    \"Therefore, log fitness can be much higher than the percentage of perfectly fitting traces.\"\n",
    ")\n"
   ],
   "id": "8319465bc1accded"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

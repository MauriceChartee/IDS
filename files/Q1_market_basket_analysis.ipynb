{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T09:54:26.514511Z",
     "start_time": "2025-12-10T09:54:24.818292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import the necessary modules\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules"
   ],
   "id": "76713c937af73cad",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T09:54:26.850131Z",
     "start_time": "2025-12-10T09:54:26.554330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "basket_items = pd.read_csv(\"groceries_basket.csv\")\n",
    "basket_items.head()"
   ],
   "id": "202dc25ef58f0d8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   order_id  product_id                          product_name      category  \\\n",
       "0         1       49302                      Bulgarian Yogurt    dairy eggs   \n",
       "1         1       10246                 Organic Celery Hearts       produce   \n",
       "2         1       43633  Lightly Smoked Sardines in Olive Oil  canned goods   \n",
       "3         1       13176                Bag of Organic Bananas       produce   \n",
       "4         1       47209                  Organic Hass Avocado       produce   \n",
       "\n",
       "   add_to_cart_sequence_index  \n",
       "0                           1  \n",
       "1                           2  \n",
       "2                           3  \n",
       "3                           4  \n",
       "4                           5  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>add_to_cart_sequence_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>Bulgarian Yogurt</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>Organic Celery Hearts</td>\n",
       "      <td>produce</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>Lightly Smoked Sardines in Olive Oil</td>\n",
       "      <td>canned goods</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>Bag of Organic Bananas</td>\n",
       "      <td>produce</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>47209</td>\n",
       "      <td>Organic Hass Avocado</td>\n",
       "      <td>produce</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T09:54:28.263189Z",
     "start_time": "2025-12-10T09:54:28.240124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# items\n",
    "n_items = basket_items['product_id'].nunique()\n",
    "print(f'Number of unique items: {n_items}')\n",
    "# orders\n",
    "n_orders = basket_items['order_id'].nunique()\n",
    "print(f'Number of unique orders: {n_orders}')\n",
    "# basket_items\n",
    "n_basket_items = len(basket_items)\n",
    "print(f'Number of basket items: {n_basket_items}')"
   ],
   "id": "c4feddc9498c07d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique items: 26548\n",
      "Number of unique orders: 64864\n",
      "Number of basket items: 573124\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# a) Product Frequencies",
   "id": "cf1e1b7dc73ef6e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Support count per product = number of distinct orders containing the product\n",
    "product_support = (\n",
    "    basket_items.groupby(\"product_id\")[\"order_id\"]\n",
    "    .nunique()\n",
    "    .rename(\"support_count\")\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "if \"n_orders\" not in globals():\n",
    "    n_orders = basket_items[\"order_id\"].nunique()\n",
    "\n",
    "support_threshold_1pct = int(np.ceil(0.01 * n_orders))\n",
    "mean_support_count = product_support.mean()\n",
    "median_support_count = product_support.median()\n",
    "\n",
    "print(\"1) Minimum support count for >= 1% support:\", support_threshold_1pct)\n",
    "print(\"2) Mean support count across all products:\", mean_support_count)\n",
    "print(\"3) Median support count across all products:\", median_support_count)\n",
    "\n",
    "# Helper mapping for later tasks (product_id -> product_name)\n",
    "product_name_by_id = (\n",
    "    basket_items.drop_duplicates(\"product_id\").set_index(\"product_id\")[\"product_name\"]\n",
    ")\n"
   ],
   "id": "dccd22ec7c32a9f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# b) + c) Most frequent Products",
   "id": "a3bbab6c37df34e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can separate these if you want, but it makes sense to do them together.",
   "id": "a76101b1d73a3cd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Absolute + relative frequencies for the 10 most frequent products\n",
    "top10 = product_support.head(10).to_frame()\n",
    "top10[\"support\"] = top10[\"support_count\"] / n_orders\n",
    "top10[\"product_name\"] = top10.index.map(product_name_by_id)\n",
    "top10 = top10[[\"product_name\", \"support_count\", \"support\"]]\n",
    "\n",
    "display(top10)\n",
    "\n",
    "top10_ids = top10.index.tolist()\n",
    "\n",
    "# Max possible support for a 3-itemset using this list\n",
    "# (upper bound = min support among the chosen 3 items)\n",
    "top3_ids = top10.index[:3].tolist()\n",
    "max_possible_support_count = int(top10.loc[top3_ids, \"support_count\"].min())\n",
    "max_possible_support = max_possible_support_count / n_orders\n",
    "\n",
    "print(\"\\nMax possible support count for a 3-itemset (upper bound):\", max_possible_support_count)\n",
    "print(\"Max possible support (relative):\", max_possible_support)\n",
    "print(\"Itemset product IDs:\", top3_ids)\n",
    "print(\"Itemset product names:\", [product_name_by_id.loc[i] for i in top3_ids])\n",
    "\n",
    "# c) How many orders actually contain all three products?\n",
    "orders_with_all_three = (\n",
    "    basket_items[basket_items[\"product_id\"].isin(top3_ids)]\n",
    "    .groupby(\"order_id\")[\"product_id\"]\n",
    "    .nunique()\n",
    "    .eq(3)\n",
    ")\n",
    "actual_intersection_count = int(orders_with_all_three.sum())\n",
    "\n",
    "print(\"\\nOrders containing all three products:\", actual_intersection_count)\n",
    "print(\"Support of the 3-itemset (relative):\", actual_intersection_count / n_orders)\n",
    "\n",
    "print(\n",
    "    \"\\nExplanation: 'Banana' and 'Bag of Organic Bananas' are substitutes, so customers usually buy one of them \"\n",
    "    \"instead of both; therefore the triple intersection with 'Organic Strawberries' is very rare.\"\n",
    ")\n"
   ],
   "id": "6d5b12dba9536cec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# d) + e) Product Categories",
   "id": "e9ca0f02a16b0df4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You don't really need the notebook for e)",
   "id": "a62f672b74f0ea21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# d) Total number of sold products (basket items) per category\n",
    "items_sold_per_category = (\n",
    "    basket_items.groupby(\"category\").size().rename(\"items_sold\").sort_index()\n",
    ")\n",
    "\n",
    "ax = items_sold_per_category.plot(kind=\"bar\", figsize=(12, 4))\n",
    "ax.set_title(\"Total number of sold products (basket items) per category\")\n",
    "ax.set_xlabel(\"category\")\n",
    "ax.set_ylabel(\"items_sold\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# d) Mean + median number of items per order for each product category\n",
    "items_per_order_per_category = (\n",
    "    basket_items.groupby([\"category\", \"order_id\"]).size().rename(\"items_per_order\")\n",
    ")\n",
    "category_order_stats = (\n",
    "    items_per_order_per_category.groupby(\"category\").agg([\"mean\", \"median\"]).sort_index()\n",
    ")\n",
    "\n",
    "ax = category_order_stats.plot(kind=\"bar\", figsize=(12, 4))\n",
    "ax.set_title(\"Mean and median items per order per category\")\n",
    "ax.set_xlabel(\"category\")\n",
    "ax.set_ylabel(\"items_per_order\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# e) What mean vs median tell you about beverages\n",
    "bev_mean = category_order_stats.loc[\"beverages\", \"mean\"]\n",
    "bev_median = category_order_stats.loc[\"beverages\", \"median\"]\n",
    "\n",
    "print(f\"Beverages - mean items/order: {bev_mean:.3f}, median items/order: {bev_median:.1f}\")\n",
    "print(\n",
    "    \"Interpretation: The median of 1 shows that most beverage-containing orders include exactly one beverage item. \"\n",
    "    \"The higher mean indicates that a smaller number of orders contain multiple beverage items, which pulls the average up.\"\n",
    ")\n"
   ],
   "id": "80bb8f753e254165"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# f) Frequent Itemsets",
   "id": "634e54e4afe996ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T09:54:31.622525Z",
     "start_time": "2025-12-10T09:54:31.586818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# use the provided frequent itemsets\n",
    "frequent_itemsets = pd.read_csv(\"frequent_itemsets.csv\")\n",
    "\n",
    "# Parse strings like \"frozenset({47209, 24852})\" into Python frozensets of ints\n",
    "frequent_itemsets[\"itemset_ids\"] = frequent_itemsets[\"itemsets\"].astype(str).apply(\n",
    "    lambda s: frozenset(int(x) for x in re.findall(r\"\\d+\", s))\n",
    ")\n",
    "frequent_itemsets[\"size\"] = frequent_itemsets[\"itemset_ids\"].apply(len)\n",
    "\n",
    "# Overwrite the original string column with real frozensets so mlxtend can use it\n",
    "frequent_itemsets[\"itemsets\"] = frequent_itemsets[\"itemset_ids\"]\n",
    "\n",
    "# Ensure we have a product_id -> name mapping (defined in a), even if cells were run out of order\n",
    "if \"product_name_by_id\" not in globals():\n",
    "    product_name_by_id = (\n",
    "        basket_items.drop_duplicates(\"product_id\")\n",
    "        .set_index(\"product_id\")[\"product_name\"]\n",
    "    )\n",
    "\n",
    "# 1) Names of the products in the largest frequent itemset\n",
    "max_size = frequent_itemsets[\"size\"].max()\n",
    "largest_itemsets = frequent_itemsets.loc[\n",
    "    frequent_itemsets[\"size\"].eq(max_size), \"itemset_ids\"\n",
    "].tolist()\n",
    "\n",
    "print(\"1) Largest frequent itemset size:\", int(max_size))\n",
    "print(\"   Number of largest itemsets:\", len(largest_itemsets))\n",
    "for i, itemset_ids in enumerate(largest_itemsets, start=1):\n",
    "    ids_sorted = sorted(itemset_ids)\n",
    "    print(f\"   Itemset {i} (IDs):\", ids_sorted)\n",
    "    print(\"   Names:\")\n",
    "    for pid in ids_sorted:\n",
    "        print(\"   -\", product_name_by_id.get(pid, f\"<unknown {pid}>\"))\n",
    "\n",
    "# 2) How many frequent itemsets of size 2 or larger (absolute and relative)?\n",
    "n_ge2 = int((frequent_itemsets[\"size\"] >= 2).sum())\n",
    "share_ge2 = n_ge2 / len(frequent_itemsets)\n",
    "print(\"\\n2) Frequent itemsets with size >= 2:\", n_ge2)\n",
    "print(\"   Relative:\", share_ge2)\n",
    "\n",
    "# 3) Which item appears in the most frequent itemsets?\n",
    "item_counts = Counter()\n",
    "for s in frequent_itemsets[\"itemset_ids\"]:\n",
    "    item_counts.update(s)\n",
    "\n",
    "most_common_item_id, most_common_item_count = item_counts.most_common(1)[0]\n",
    "print(\"\\n3) Item in the most frequent itemsets:\", most_common_item_id)\n",
    "print(\"   Name:\", product_name_by_id.get(most_common_item_id, f\"<unknown {most_common_item_id}>\"))\n",
    "print(\"   Appears in:\", most_common_item_count)\n",
    "\n",
    "# 4) How many products appear in only a single frequent itemset?\n",
    "n_only_once = sum(1 for v in item_counts.values() if v == 1)\n",
    "print(\"\\n4) Products appearing in only one frequent itemset:\", n_only_once)\n",
    "\n",
    "frequent_itemsets.head()"
   ],
   "id": "58651eff55f8312f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    support itemsets\n",
       "0  0.118725  (13176)\n",
       "1  0.055578  (47209)\n",
       "2  0.015432  (22035)\n",
       "3  0.008048  (10246)\n",
       "4  0.029462  (46979)"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118725</td>\n",
       "      <td>(13176)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055578</td>\n",
       "      <td>(47209)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015432</td>\n",
       "      <td>(22035)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008048</td>\n",
       "      <td>(10246)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029462</td>\n",
       "      <td>(46979)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# g) + h) Category Sets",
   "id": "887c09409756d5f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### h) Why the observations are not unexpected\n\n1. Produce accounts for the largest share of basket items and most of the top-frequency products are produce. Therefore, produce-produce combinations are most likely to reach the minimum support and become frequent itemsets.\n2. Since produce items are present in a large fraction of orders, including at least one produce item greatly increases the chance of surpassing the support threshold. Hence, nearly all frequent itemsets include produce and only few itemsets without produce remain.\n3. Although many orders contain no beverages, the customers who do buy beverages often buy the same beverage combinations repeatedly, so some beverage-only itemsets still reach the minimum support. The fact that only a few beverage-only itemsets are frequent indicates that frequent beverage sales are concentrated on a small subset of beverages (limited diversity among the frequent beverages).",
   "id": "7b1ad36e0ef2757c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# g) Consider frequent itemsets with size >= 2 and convert them to category sets\n",
    "product_category_by_id = (\n",
    "    basket_items.drop_duplicates(\"product_id\").set_index(\"product_id\")[\"category\"]\n",
    ")\n",
    "\n",
    "fi_ge2 = frequent_itemsets[frequent_itemsets[\"itemsets\"].apply(len) >= 2].copy()\n",
    "fi_ge2[\"category_set\"] = fi_ge2[\"itemsets\"].apply(\n",
    "    lambda s: frozenset(product_category_by_id.get(pid, \"UNKNOWN\") for pid in s)\n",
    ")\n",
    "\n",
    "category_set_counts = fi_ge2[\"category_set\"].value_counts()\n",
    "category_sets = category_set_counts.rename_axis(\"category_set\").reset_index(name=\"frequency\")\n",
    "category_sets[\"label\"] = category_sets[\"category_set\"].apply(\n",
    "    lambda s: \"{\" + \", \".join(sorted(s)) + \"}\"\n",
    ")\n",
    "\n",
    "display(category_sets)\n",
    "\n",
    "# Plot: category sets ordered by frequency (descending)\n",
    "ax = category_sets.set_index(\"label\")[\"frequency\"].plot(kind=\"bar\", figsize=(12, 4))\n",
    "ax.set_title(\"Category-set frequencies for frequent itemsets (size >= 2)\")\n",
    "ax.set_xlabel(\"category set\")\n",
    "ax.set_ylabel(\"frequency (# frequent itemsets)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Helpful numbers for h)\n",
    "n_itemsets_ge2 = len(fi_ge2)\n",
    "n_produce_only = int(category_set_counts.get(frozenset({\"produce\"}), 0))\n",
    "n_without_produce = int(fi_ge2[\"category_set\"].apply(lambda s: \"produce\" not in s).sum())\n",
    "n_beverages_only = int(category_set_counts.get(frozenset({\"beverages\"}), 0))\n",
    "\n",
    "print(\"Frequent itemsets with size >= 2:\", n_itemsets_ge2)\n",
    "print(\"- only produce:\", n_produce_only)\n",
    "print(\"- without produce:\", n_without_produce)\n",
    "print(\"- only beverages:\", n_beverages_only)\n"
   ],
   "id": "c0055986b2040ce5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# i) Association Rules and Frequent Items",
   "id": "6821a8e48c812a7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You don't really need the notebook for j)",
   "id": "1265fb3c118795d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T09:58:52.721444Z",
     "start_time": "2025-12-10T09:58:52.701462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# i) Determine association rules with support count >= 100 and confidence >= 0.2\n",
    "if \"n_orders\" not in globals():\n",
    "    n_orders = basket_items[\"order_id\"].nunique()\n",
    "\n",
    "min_support = 100 / n_orders\n",
    "\n",
    "# mlxtend expects a DataFrame with columns: support, itemsets\n",
    "rules = association_rules(\n",
    "    frequent_itemsets[[\"support\", \"itemsets\"]],\n",
    "    metric=\"confidence\",\n",
    "    min_threshold=0.2,\n",
    ")\n",
    "\n",
    "# Ensure the minimum support count of 100 (given the mined itemsets, this should already hold)\n",
    "rules = rules[rules[\"support\"] >= min_support].copy()\n",
    "\n",
    "# Add absolute support count for convenience\n",
    "rules[\"support_count\"] = (rules[\"support\"] * n_orders).round().astype(int)\n",
    "\n",
    "# Drop extra metrics (depending on mlxtend version)\n",
    "rules = rules.drop(\n",
    "    columns=[\n",
    "        \"representativity\",\n",
    "        \"leverage\",\n",
    "        \"conviction\",\n",
    "        \"zhangs_metric\",\n",
    "        \"jaccard\",\n",
    "        \"certainty\",\n",
    "        \"kulczynski\",\n",
    "    ],\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "\n",
    "rules.head()"
   ],
   "id": "5e092f11c86c5696",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      antecedents consequents  antecedent support  consequent support  \\\n",
       "0         (47209)     (13176)            0.055578            0.118725   \n",
       "1         (47209)     (21137)            0.055578            0.084484   \n",
       "2  (13176, 47209)     (21137)            0.018423            0.084484   \n",
       "3  (13176, 21137)     (47209)            0.023942            0.055578   \n",
       "4  (47209, 21137)     (13176)            0.011486            0.118725   \n",
       "\n",
       "    support  confidence      lift  \n",
       "0  0.018423    0.331484  2.792025  \n",
       "1  0.011486    0.206657  2.446100  \n",
       "2  0.005396    0.292887  3.466756  \n",
       "3  0.005396    0.225370  4.055039  \n",
       "4  0.005396    0.469799  3.957021  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(47209)</td>\n",
       "      <td>(13176)</td>\n",
       "      <td>0.055578</td>\n",
       "      <td>0.118725</td>\n",
       "      <td>0.018423</td>\n",
       "      <td>0.331484</td>\n",
       "      <td>2.792025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(47209)</td>\n",
       "      <td>(21137)</td>\n",
       "      <td>0.055578</td>\n",
       "      <td>0.084484</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.206657</td>\n",
       "      <td>2.446100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(13176, 47209)</td>\n",
       "      <td>(21137)</td>\n",
       "      <td>0.018423</td>\n",
       "      <td>0.084484</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.292887</td>\n",
       "      <td>3.466756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(13176, 21137)</td>\n",
       "      <td>(47209)</td>\n",
       "      <td>0.023942</td>\n",
       "      <td>0.055578</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.225370</td>\n",
       "      <td>4.055039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(47209, 21137)</td>\n",
       "      <td>(13176)</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.118725</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.469799</td>\n",
       "      <td>3.957021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# i) Answers\n",
    "\n",
    "# 1) Mean and median lift across all rules\n",
    "mean_lift = rules[\"lift\"].mean()\n",
    "median_lift = rules[\"lift\"].median()\n",
    "print(\"1) Mean lift:\", mean_lift)\n",
    "print(\"   Median lift:\", median_lift)\n",
    "\n",
    "# 2) / 3) Count rules that contain at least one of the top-10 products\n",
    "if \"top10_ids\" not in globals():\n",
    "    product_support_tmp = (\n",
    "        basket_items.groupby(\"product_id\")[\"order_id\"].nunique().sort_values(ascending=False)\n",
    "    )\n",
    "    top10_ids = product_support_tmp.head(10).index.tolist()\n",
    "\n",
    "top10_set = set(top10_ids)\n",
    "\n",
    "n_top10_in_antecedent = int(\n",
    "    rules[\"antecedents\"].apply(lambda s: len(set(s) & top10_set) > 0).sum()\n",
    ")\n",
    "n_top10_in_consequent = int(\n",
    "    rules[\"consequents\"].apply(lambda s: len(set(s) & top10_set) > 0).sum()\n",
    ")\n",
    "\n",
    "print(\"\\n2) #rules with >= 1 top-10 product in the antecedent:\", n_top10_in_antecedent)\n",
    "print(\"3) #rules with >= 1 top-10 product in the consequent:\", n_top10_in_consequent)\n"
   ],
   "id": "2a8c40bbdfa9c574"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# j) Confidence",
   "id": "4ac1d5b2aaeadb1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# j) Rule with the highest confidence\n",
    "best_rule = rules.sort_values([\"confidence\", \"support\"], ascending=[False, False]).iloc[0]\n",
    "\n",
    "def itemset_to_names(itemset):\n",
    "    return [product_name_by_id.get(pid, str(pid)) for pid in sorted(itemset)]\n",
    "\n",
    "ant_names = itemset_to_names(best_rule[\"antecedents\"])\n",
    "con_names = itemset_to_names(best_rule[\"consequents\"])\n",
    "\n",
    "display(best_rule.to_frame().T)\n",
    "\n",
    "print(\"Rule:\")\n",
    "print(\"A =\", ant_names)\n",
    "print(\"B =\", con_names)\n",
    "print(\n",
    "    f\"support_count={best_rule['support_count']}, confidence={best_rule['confidence']:.3f}, lift={best_rule['lift']:.3f}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\nInterpretation: Customers who buy the antecedent products also buy the consequent products with the shown confidence. \"\n",
    "    \"Since the lift is > 1, the consequent becomes more likely than under independence.\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\nWhy frequent items often appear as consequents: Confidence conditions on the antecedent (support(A) is the denominator). \"\n",
    "    \"If a very frequent product were the antecedent, achieving a very high confidence would require the consequent to appear in a large fraction of all those orders. \"\n",
    "    \"In contrast, predicting a frequent product as the consequent is easier because it already has a high base rate.\"\n",
    ")\n"
   ],
   "id": "5dca97288d515126"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# k) No very frequent products, Lift",
   "id": "e3f24e0612ae5e2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# k) Rules without any of the top-10 most frequent products in antecedent or consequent\n",
    "if \"top10_ids\" not in globals():\n",
    "    product_support_tmp = (\n",
    "        basket_items.groupby(\"product_id\")[\"order_id\"].nunique().sort_values(ascending=False)\n",
    "    )\n",
    "    top10_ids = product_support_tmp.head(10).index.tolist()\n",
    "\n",
    "top10_set = set(top10_ids)\n",
    "\n",
    "mask_no_top10 = (\n",
    "    rules[\"antecedents\"].apply(lambda s: len(set(s) & top10_set) == 0)\n",
    "    & rules[\"consequents\"].apply(lambda s: len(set(s) & top10_set) == 0)\n",
    ")\n",
    "rules_no_top10 = rules[mask_no_top10].copy()\n",
    "\n",
    "print(\"Overall rules:\", len(rules))\n",
    "print(\"- mean lift:\", rules[\"lift\"].mean())\n",
    "print(\"- median lift:\", rules[\"lift\"].median())\n",
    "\n",
    "print(\"\\nRules without top-10 products:\", len(rules_no_top10))\n",
    "print(\"- mean lift:\", rules_no_top10[\"lift\"].mean())\n",
    "print(\"- median lift:\", rules_no_top10[\"lift\"].median())\n",
    "\n",
    "display(\n",
    "    rules_no_top10.sort_values(\"lift\", ascending=False)\n",
    "    .head(10)[[\"antecedents\", \"consequents\", \"support_count\", \"confidence\", \"lift\"]]\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\nStriking observation: These rules typically have a much higher lift than the overall set of rules. \"\n",
    "    \"This is not surprising because lift compares observed co-occurrence to what we would expect under independence, \"\n",
    "    \"and for less frequent items the expected co-occurrence is very smallâ€”so strong co-purchases lead to large lift values.\"\n",
    ")\n"
   ],
   "id": "67064d4f1c95578a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# l) Sub-sequences",
   "id": "879ddb506fc6c195"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T09:23:46.735751Z",
     "start_time": "2025-12-10T09:23:46.730557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# function from the exercise notebook\n",
    "def contained(is_seq1, is_seq2):\n",
    "    size1 = len(is_seq1)\n",
    "    size2 = len(is_seq2)\n",
    "\n",
    "    if size1 > size2:\n",
    "        return False\n",
    "\n",
    "    last_1 = 0\n",
    "    last_2 = 0\n",
    "\n",
    "    while last_1 < size1 and last_2 < size2:\n",
    "        item1 = is_seq1[last_1]\n",
    "        item2 = is_seq2[last_2]\n",
    "        if item1 == item2:\n",
    "            last_1 += 1\n",
    "        last_2 += 1\n",
    "\n",
    "    if last_1 == size1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "id": "791ee79e4214b896",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# l) Subsequence support counts for bi-directional singleton rules\n",
    "# The assignment calls this column add_to_cart_order; in this dataset it is add_to_cart_sequence_index\n",
    "sequence_col = (\n",
    "    \"add_to_cart_order\"\n",
    "    if \"add_to_cart_order\" in basket_items.columns\n",
    "    else \"add_to_cart_sequence_index\"\n",
    ")\n",
    "\n",
    "# Only consider rules with single-item antecedent and consequent\n",
    "rules_single = rules[\n",
    "    (rules[\"antecedents\"].apply(len) == 1) & (rules[\"consequents\"].apply(len) == 1)\n",
    "].copy()\n",
    "\n",
    "# Extract directed pairs (a -> b)\n",
    "directed_pairs = [\n",
    "    (next(iter(a)), next(iter(b)))\n",
    "    for a, b in zip(rules_single[\"antecedents\"], rules_single[\"consequents\"])\n",
    "]\n",
    "directed_set = set(directed_pairs)\n",
    "\n",
    "# Keep pairs where both directions exist (a -> b and b -> a)\n",
    "bidirectional_pairs = sorted(\n",
    "    {tuple(sorted((a, b))) for (a, b) in directed_set if (b, a) in directed_set}\n",
    ")\n",
    "\n",
    "print(\"Number of bi-directional singleton pairs:\", len(bidirectional_pairs))\n",
    "bidirectional_pairs\n",
    "\n",
    "# Compute support counts for subsequences <a,b> and <b,a>\n",
    "unique_products = sorted({pid for pair in bidirectional_pairs for pid in pair})\n",
    "\n",
    "subset = basket_items[basket_items[\"product_id\"].isin(unique_products)][\n",
    "    [\"order_id\", \"product_id\", sequence_col]\n",
    "]\n",
    "\n",
    "# Position of each product in each order (min index; products occur at most once in this dataset)\n",
    "positions = subset.groupby([\"order_id\", \"product_id\"])[sequence_col].min().unstack(\"product_id\")\n",
    "\n",
    "rows = []\n",
    "for a, b in bidirectional_pairs:\n",
    "    pa = positions[a]\n",
    "    pb = positions[b]\n",
    "    both = pa.notna() & pb.notna()\n",
    "\n",
    "    support_ab = int((both & (pa < pb)).sum())\n",
    "    support_ba = int((both & (pb < pa)).sum())\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"a_id\": a,\n",
    "            \"a_name\": product_name_by_id.get(a, str(a)),\n",
    "            \"b_id\": b,\n",
    "            \"b_name\": product_name_by_id.get(b, str(b)),\n",
    "            \"support_<a,b>\": support_ab,\n",
    "            \"support_<b,a>\": support_ba,\n",
    "            \"orders_with_both\": int(both.sum()),\n",
    "        }\n",
    "    )\n",
    "\n",
    "subsequence_support = pd.DataFrame(rows).sort_values(\"orders_with_both\", ascending=False)\n",
    "display(subsequence_support)\n"
   ],
   "id": "5ff61bfd2fb4819f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# m) Rules with support count > 99, confidence > 0.2, Lift < 1",
   "id": "655be3d53d2f6a55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You don't need any new calculations for this. Rather consult the lecture slides and your answer for b)",
   "id": "4f856a7094bbf74c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
